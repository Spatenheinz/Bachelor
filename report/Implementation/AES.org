** AES

*** naive
:PROPERTIES:
:UNNUMBERED: nil
:CUSTOM_ID: AESnaive
:END:
Just like for the other algorithms AES can naively be implemented as a single simple process. That is we could implement the SME implentation of AES as a single process that can do both encryption and decryption and then have some checks in the ~OnTick~ function. This however poses some unwanted effects. First we add unecessary complication to the process as it would have to multiple things at once. Furthermore and more importantly a combined encrypter/decrypter reduces the utilizations of the library. Since AES is a block cypher and rarely only need to encrypt a block of 128 bits a sequence of blocks needs to be encrypted. This naive approach is not necessarily bad for some of the modes of operations such as Electronic Codebook (ECB) (which never really should be used anyway), Cipher Block chaining (CBC) (which eliminates parallelism) etc. as these will need a decryption algorithm. However is the programmer using this library choosing to operate under a Counter mode (CTR) or Galois-counter mode (GCM) the decryption algorithm itself would be unecessary as these modes uses the encryption function to both encrypt and decrypt. Thus in a hypotetical scenario where the design includes both encryption and decryption might take up 40 pct. of an FPGA and a design with only encryption would take up 20 pct. it is clear to see how many ressources are wasted. Thus we have decided that for the basecase implementation that encryption and decryption should be seperate processes. We will only go over the implementation of encryption as the process for decryption is the exact inverse computationally as described in section \ref{AESalg} and the structure thus follows symmetrically. For the design a single bus with 4 fields as seen below suffices. It consists of two Valid flags which works in a similar matter to the one described for MD5. Furthermore there is two byte arrays with the size of ~BLOCK_SIZE~ = 128 as this implementation is a 128 bit key AES. We have one array for storing the data and one for storing the key. Once again we dont want to make the process itself flexible with multiple AES versions as it will reduce the resource utilization on an FPGA. The reason for this is the optionality of additional rounds for a 256 bit key version would map these extra computations to hardware which will make the circuit more complex and harder for vivado to route the design and will have a harder time meeting the timing constraints. In section \ref{results} we will take a short look at this. If 128 key encryption suffices the overhead from including the 4 extra rounds for 256 is wasteful.

Notice furthermore, the bus is named IPlainText but could just as well have been called IData or something similar as the same bus can be used for both the plaintext and the cypher as the algorithm is symmetrical. For the output bus we however dont really have to output the key, assuming the result is send back to the device who called the function.
#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC csharp
public interface IPlainText : IBus {
    [InitialValue(false)]
    bool ValidKey { get; set; }

    [FixedArrayLength(BLOCK_SIZE)]
    IFixedArray<byte> Key { get; set; }

    [InitialValue(false)]
    bool ValidData { get; set; }
    [FixedArrayLength(BLOCK_SIZE)]
    IFixedArray<byte> Data { get; set; }

}
#+END_SRC
For the actual AES process we follow the T-box approach described earlier, as we want the throughput of our FPGA to be as efficient as possible despite lacking AES specific instructions such as, ~GF2P8AFFINEINVQB~, ~GF2P8AFFINEQB~ and ~GF2P8MULB~.
*** optimisation 1
:PROPERTIES:
:UNNUMBERED: nil
:CUSTOM_ID: AESopt
:END:
AES have shown to be quite fast even in the implementation, however its should still be a quite slow approach compared to a pipelined solution, as long as the FPGA can handle the additional logic. Exactly as the other algorithms. We notice that AES likewise uses rounds and the single process from before can be divided such that each round can is its own process. We have tried two solutions this way.

The first solution will merely be the original process split up into smaller parts. This is fairly easy to implement, but it has one flaw which might underutilize the LUT's of the FPGA, since each process will only know about each other through a bus and henceforth not have access to the same lookup tables/T-boxes. Coroally every process that needs access to one of the lookup tables will have to have it defined for itself. Argueably this is an wasteful approach as each process will have to use its own 4KB of T-boxes, which sums up to 36KB. Hence this could be wasteful and use too many LUTs leading to a worse clock rating.

If there is not enough LUTs we can use the block RAM (BRAM) to our advantage. We can utilize BRAM through SME using ~Components~. To fully utilize the BRAM we will be using the True Dual Port interface, such that we can place multiple T-Boxes in each BRAM without loosing utilization. We can further safely do this as we never write to the BRAM and thus the memory should be as predicted. One thing to be aware of when using BRAM is that it will take 2 clock cycles for a data transaction to happen. With this restriction, there are some considerations to have in mind, should the Tboxes be crammed into a single BRAM, thus having more clockcycles as we can only read a single address at a time, or should we distribute them out on multiple BRAMs to be able to do muliple lookups in each cycle. An approach which would max out the BRAM usage would look as follows:

A single block of message will include 9 rounds that requires 16 lookups. we could arange the T-Boxes as in Figure\ref{}, with 2 T-boxes in each BRAM. This would not maximize the memory usage as we far from fill the 32 Kbits of memory. But we loose no performance speedwise. If a single process then has access to two dual ports BRAMs we would require 18 BRAMs in total for full utilization. Say
