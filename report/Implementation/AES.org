** AES

*** Naive
:PROPERTIES:
:UNNUMBERED: nil
:CUSTOM_ID: AESnaive
:END:
Just like for the other algorithms, AES can naively be implemented as a single simple process. That is, we could implement the SME implementation of AES as a single process that can do both encryption and decryption and then have some checks in the ~OnTick~ function. This, however, poses some unwanted effects. First, we add unnecessary complications to the process as it would have to multiple things at once. Furthermore, and more importantly, a combined encrypter/decrypter reduces the utilization of the library. Since AES is a block cipher and rarely only needs to encrypt a block of 128 bits, a sequence of blocks needs to be encrypted. This naive approach is not necessarily bad for some of the modes of operations such as Electronic Codebook (ECB) (which never really should be used anyway), Cipher Block chaining (CBC) (which eliminates parallelism), etc. as these will need a decryption algorithm. However, the most used modes: Counter mode (CTR) and Galois-counter mode (GCM), use the encryption algorithm for both encryption and decryption. Thus in a hypothetical scenario where the design includes both encryption and decryption might take up 40 pct. of an FPGA, and a design with only encryption would take up 20 pct. It is clear to see how many resources are wasted. Thus we have decided that for the base case implementation that encryption and decryption should be separate processes. We will only go over the implementation of encryption as the process for decryption is the exact inverse computationally as described in section \ref{AESalg} and the structure thus follows symmetrically. For the design, a single bus with 4 fields, as seen below, suffices. It consists of two Valid flags, which work similarly to the one described for MD5.
Furthermore, there are two-byte arrays with the size of ~BLOCK_SIZE~ = 128 as this implementation is a 128-bit key AES. We have one array for storing the data and one for storing the key. Once again, we don't want to make the process itself flexible with multiple AES versions as it will reduce the resource utilization on an FPGA. This is because the optionality of additional rounds for a 256-bit key version would map these extra computations to hardware, making the circuit more complex and more demanding for Vivado to route the design and have a harder time meeting the timing constraints. In Section \ref{sec:AESperformance} we will take a brief look at this. If 128 key encryption suffices, the overhead from including the 4 extra rounds for 256 is wasteful.

Notice furthermore, the bus is named IPlainText but could just as well have been called IData or something similar as the same bus can be used for both the plaintext and the cipher as the algorithm is symmetrical. However, for the output bus, we don't have to output the key, assuming the result is sent back to the device that called the function.

#+ATTR_LATEX: :options frame=single
#+BEGIN_SRC csharp
public interface IPlainText : IBus {
    [InitialValue(false)]
    bool ValidKey { get; set; }

    [FixedArrayLength(BLOCK_SIZE)]
    IFixedArray<byte> Key { get; set; }

    [InitialValue(false)]
    bool ValidData { get; set; }
    [FixedArrayLength(BLOCK_SIZE)]
    IFixedArray<byte> Data { get; set; }

}
#+END_SRC
For the actual AES process, we follow the T-box approach described earlier, as we want the throughput of our FPGA to be as efficient as possible despite lacking AES-specific instructions such as ~GF2P8AFFINEINVQB~, ~GF2P8AFFINEQB~ and ~GF2P8MULB~.
*** Optimisation 1
:PROPERTIES:
:UNNUMBERED: nil
:CUSTOM_ID: AESopt
:END:
AES has shown to be quite fast even in the naive implementation (see Section \ref{sec:AESperformance}); however, it should still be a reasonably slow approach compared to a pipelined solution, as long as the FPGA can handle the additional logic. Exactly as the other algorithms. We notice that AES likewise uses rounds, and the single process from before can be divided such that each round can is its process. We have tried two solutions this way.

The first solution will merely be the original process split up into smaller parts. This is relatively easy to implement, but it has one flaw which might underutilize the LUT's of the FPGA since each process will only know about each other through a bus and henceforth not have access to the same lookup tables/T-boxes. Corollary, every process that needs access to one of the lookup tables will have to have it defined for itself. Arguably this is a wasteful approach as each process will have to use its own 4KB of T-boxes, which sums up to 36KB. Hence this could be wasteful and use too many LUTs leading to a worse clock rating.

If there are not enough LUTs, we can use the block RAM (BRAM) to our advantage. We can utilize BRAM through SME using ~Components~. To fully utilize the BRAM, we will be using the True Dual Port interface to place multiple T-Boxes in each BRAM without losing utilization. We can further safely do this as we never write to the BRAM, and thus the memory should be as predicted. One thing to be aware of when using BRAM is that it will take 2 clock cycles for a data transaction to happen. With this restriction, there are some considerations to have in mind, should the T-boxes be crammed into a single BRAM, thus having more clock cycles as we can only read a single address at a time, or should we distribute them out on multiple BRAMs to be able to do multiple lookups in each cycle. An approach that would max out the BRAM usage would look as follows:

A single block of the message will include 9 rounds that require 16 lookups. We could arrange the T-Boxes as in Figure\ref{}, with 2 T-boxes in each BRAM. This would not maximize the memory usage as we far from fill the 32 Kbits of memory. But we lose no performance speed-wise. If a single process then has access to two dual ports BRAMs, we would require 18 BRAMs in total for full utilization. \footnote{TODO: this sections should be revised}
