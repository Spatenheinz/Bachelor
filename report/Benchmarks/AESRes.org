** AES
\label{sec:AESperformance}
\footnote{This section is not done}
*** Throughput
In the implementation section we described how we rejected to make a solution that was flexible in its key-size. The results shown in Table \ref{tab:AESversions} hint that this have good impact on the performance. Comparing our solution to the solution presented in the SME github repository, which is more flexible in the key size, our solution outperforms this by a factor of 1.66, as it is reported to have a throughput of 1.92Gbps(240MB/s)\cite{sme}. This shows that we can tradeoff some flexibility for a significant speedup.
#+BEGIN_EXPORT latex
\begin{table}[!htb]
\centering
\captionsetup{width=.8\linewidth}
\begin{tabular}{c c c c c c}
\hline
Version & f$_{max}$(Mhz) & clocks$_{high}$ & TP(MBps)$_{high}$ & clocks$_{low}$ & TP(MBps)$_{low}$ & LUT & FF\\
\hline
Naive      &   X & b          & X    & X     & X\\
TBox       &  25 & b           & 400 & 16458 & 3195\\
Proc$_{4}$  &  68 & $C_{128}(3)$ & 544 & 16474 & 2817\\
Proc$_{11}$ & 208 & $C_{128}(10)$ & 1663 & 15659 & 4383\\
Proc$_{11}$ & 217 & $C_{128}(24)$ & 1662 & 15454 & 7401\\
\end{tabular}
\caption[AES: FPGA Versions]%
{Performance and statistics over the different AES implementations. f$_{max}$ is the clock rate reported from Vivado. Clocks describe how many clock cycles it takes to calculate \texttt{b} blocks, where $C_{bits}(x) = x+2 \cdot blocks \cdot bits$. The throughput (TP) is calculated as \((b_{bits}\cdot f_{max})/(clocks \cdot 8)\). LUT is the number of Look-Up Tables used in the design. FF is the reported amount of Flip Flops used. Proc$_{i}$ denotes how many ~i~ processes the 64 rounds are distributed over.}
\label{tab:AESversions}
\end{table}
#+END_EXPORT
From the different implementations as shown in Table \ref{tab:AESversions} one can see something quite interesting. In Section \ref{AESopt} we described how we would assume the reasonably large lookup tables might be using up quite a lot of the FPGAs LUTs. This is however is not the case as the naive version is using only 16500 LUTs comparing to the SHA256's 24300. Even more interesting is it that splitting the calculations up into different processes does not increase the LUT usage. This suggests that the vivado synthesizer recognises the arrays from each process to be equivlent Read Only Memory and thus can optimize it to a single table. Againts the assumptions this produces reasonable results, without having to specifically use BRAM. Simply by making each round of AES its own process we get a 4 fold increase in throughput from the naive TBox approach. We get no further improvement from reducing each process to only a half round, which might suggest the overhead from signals etc. is becoming the bottleneck.


#+BEGIN_EXPORT latex
\begin{table}[!htb]
\centering
\captionsetup{width=.8\linewidth}
\begin{tabular}{c c c c c c c c}
\hline
\textbf{Version} & Naive & Proc$_{11}$ & C\# & C & OpenSLL$_{low}$ & OpenSLL$_{high}$\\
\hline
\textbf{TP(MBps)} & 400 & 1963 &    70& 198 & 72  & 89\\
 &                &     &      & 1699 & 340 & 847 & 5722
\end{tabular}
\caption[AES: FPGA and CPU comparisons]%
{Performance comparison of the worst and best AES FPGA implementations and the various CPU versions. The OpenSSL is from \texttt{openssl speed -evp aes-128-ecb}. Each of the CPU implementations has two values, the first being the Pi results and the second the I5 results.}
\label{tab:AEScompare}
\end{table}
#+END_EXPORT
The results of AES is interesting compared to our other implementations in the sense that even the naive FPGA version is outperforming the CPU on the Pi. One can notice that our naive version has a throughput of 400 MB/s which is around 4.49 times as much as OpenSLL on its peak performance and that it likewise outperforms C# and our own C-version with 5.7 and 6.2 times respectively. The I5 however is quite a lot faster than the naive implementation where only our own C version is slower. The pipelined version *Proc*$_{11}$ is almost as fast as the C# version and the faster than OpenSSL at its lowerst performance. However OpenSSL at its full capacity still has around 3.4 times higher throughput. These results emphasizes the results presented from the previous sections, that a FPGA is faster at performing specific tasks than a CPU, but also shows how an ASIC, such as the AES-NI device in intel CPU's is even better at doing a specific task than an FPGA. One aspect to consider is that a Zynq board and an I5-7500 has about the same cost, hence a Zynq is cheaper than the I5 since it also needs all the other components of a computer, such as Motherboard, RAM, etc.
Even for high end FPGA's a "comparable" CPU can achieve similar performance.
An article from 2020 which compares both pipelined and non-pipelined versions of AES on FPGA's shows that a pipelined version on a Virtex-5 (costing 12000 GBP) has a throughput of 14.9 GBps\cite{Zodpe}, whereas an AMD ThreadRipper 3970x (16000DKK) can achieve 12.9 GBps, which clearly shows just how affective ASICs can be. With this in mind our results might not seem as bad.
*** Power Consumptions
\begin{figure}[H]
\centering
\subfloat[TBox version]{\includegraphics[width=6cm]{AESpower.png}}
\subfloat[Proc$_{11}$ version]{\includegraphics[width=6cm]{AESpower3.png}}
\caption[Power consumption of AES designs]
{Powerconsumption of AES designs}
\label{fig:SHA_power}
\end{figure}

*** Takeaways
