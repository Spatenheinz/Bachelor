% Created 2021-03-05 Fri 19:26
% Intended LaTeX compiler: pdflatex
\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\input{baseHeader.tex}
\assignment{} \subtitle{} \date{12 06 2021} \advisor{Advisor: Kenneth Skovhede} \frontpage{}
\author{Jacob Herbst (mwr148), Jonas Flach Jensen (sjm233)}
\date{\today}
\title{Crypto in SME for FPGA}
\hypersetup{
 pdfauthor={Jacob Herbst (mwr148), Jonas Flach Jensen (sjm233)},
 pdftitle={Crypto in SME for FPGA},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.14)},
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\newpage
\section{Introduction}
\label{sec:orgf0f5fa7}

\section{Background}
\label{sec:orga02c345}

\subsection{Field Programmable Gate Arrays}
\label{sec:org4fb8f48}
TODO: write something more in-depth.

Why use FPGA's? To get a speed increase by moving frequently used functions and calculations from the CPU to a specialized chip (the FPGA).
This will result in less time "wasted" on the CPU, and the specialized chip will ideally also be able to do the computations faster than a generic CPU.
\subsection{Synchronous Message Exchange}
\label{sec:orgaec27e9}
Synchronous Message Exchange (SME) is a programming model to enable FPGA development using high-level languages. SME is based on Communicating Sequential Processes (CSP) and at its core constructs as a strict subset of said process calculi, making use of the elements which has proven useful in hardware design\cite{sme}\footnote{sme ref}. Using the following concepts from the CSP model, SME can be derived:


\begin{itemize}
\item A program consists of a set of named processes.
\item Each process runs on its own processor with no form of sharing with other processes.
\item Concurrent processes can communicate using message passing with a \texttt{send(!)} and a \texttt{receive(?)} command. This message passing is Blocking and Non-buffered.
\end{itemize}
Without going into too much detail about the syntax and semantics of CSP\cite{CSP}, we can use the following syntax to describe a program.
\begin{itemize}
\item \texttt{x::PROCESS}, which assigns the PROCESS to the name x.
\item \texttt{x.in} is a compound name similar to an object field \texttt{in} of the object. Notice this abstraction makes the connection to SME and its C\# implementation more obvious.
\item \texttt{x.out!y.in} This is the sending message passing. It will send y.in to x.out.
\item \texttt{x.out?y.in}. This is the receiving message passing. It will read x.out to y.in.
\item \texttt{x || y} will denote two concurrent processes, x, and y.\footnote{this does not make any sense, diagrams are more readable or does it indeed makes it easier to reason about concurrency?}
\end{itemize}

Later we will show this can easily show abstractions of algorithms when using SME. SME has a similar notion of processes. There exist two types of SME processes, \texttt{simple process} and a \texttt{simulation process}. Of these, the simple process corresponds to a process in CSP as described above. Each simple process in SME will only share communication channels and constants with the other processes. For the communications channels, SME extends the concepts from CSP by using buses. Instead of using explicit naming for sources and destinations, each process will consist of a set of input and output busses that it can read and write to, respectively. Furthermore, these buses use broadcasting as means of synchronization instead of the blocking non-buffered approach.  The broadcasting happens every clock-cycle on the internal clock.
A bus is essentially just a collection of fields that can be read and written to depending on the process's access, merely a data transfer object. Here the syntax described above comes in hand. \texttt{message.text} would thus be the text field of the bus \texttt{message}. Corollary, we could define a very minimal process as such \texttt{[messageIn.text?messageOut.text]}, which would read the text field from the \texttt{messageIn} input bus and write it to the \texttt{messageOut} output bus. From these abstractions, one might be able to see how this effortlessly coincides with the hardware model.
\subsection{A crypto library}
\label{sec:orgd889226}
Cryptographic functions are used by developers across most branches, whether it'll be communicating securely over a network, or hashing programs to do version control.
So there is a motive for having a crypto library for FPGA's. In fact, such a processor has been made before. IBM created their own "IBM 4758 Secure Coprocessor"(ref. \url{https://web.archive.org/web/20170808032012/http://www.research.ibm.com/people/s/sailer/publications/2001/ibm4758.pdf}).\% Another point is modern Hardware security modules (HSM) which also does this.
However, the problem with the existing solutions is that many of them require setting up a royalty-based licensing deal, which makes it difficult to use for experimental development, small projects, and in research, and academics.
So we set out to create an open-source crypto library.

The crypto library consists of an implementation of various cryptographic functions, such as AES and SHA256. It should also have an API allowing users to utilize these functions in their projects, as they would with any other library.
These implementations should also be optimized in terms of speed so that they are competitive with the existing software solutions.
\%Creating a crypto library for FPGA's \ldots{}
\subsubsection{Hashing}
\label{sec:org14e4686}
Hashing is a mathematical concept referring to using a hash function to map some data of arbitrary size to a value of a fixed size. Cryptographic hash functions are a subset of all hash functions.
The reason for this is that for a hash function to be a cryptographic hash function it needs to uphold several properties to ensure it is secure, such as ensuring that it is hard to find collisions. Computers also have limited space in memory which limits the implementation of hash functions. Lastly and most importantly, computers can't do true randomness.
If a hash function can be implemented with a limited input space, is pseudo-random, and upholds certain properties listed below, it can be categorized as a "Cryptographic Hash Function". One such example is the outdated MD5 algorithm.
\begin{itemize}
\item It should be deterministic, as it is important that the same hash is computed given some input.
\item It is unreasonably hard to predict the hashed value. One reason for this is the requirement to exercise the avalanche effect, meaning the tiniest change in the input message would resolve in big changes in the hash.
\item It is collision-resistant, meaning it is unreasonably hard to find two distinct messages to have the same hash.
\end{itemize}

\begin{enumerate}
\item Merkle-Damgård construction
\label{sec:orgc096fae}
One way approach that is widely used in cryptographic hashing is the Merkle-Damgård construction. One of the reasons this approach is desirable when developing a cryptographic hashing algorithm is because the hash function will be collision-resistant given the compression function itself is collision-resistant.
From figure \ref{fig:Merkle} one can see the construction of the hashing function. One can see that the message will be padded to have a certain length since any compression function must work on static size. The compression function \texttt{f} will initially take two arguments, the initialization vector, and the first block. f will then produce a result of the same size as the initialization vector. This result will then be fed into the next iteration of \texttt{f} along with the second block of the message. This is repeated until the entire padded message has been processed. From here a potential finalization function can be used to improve the hash. Lastly, the hashed value will be produced.

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./Merkle.png}
\caption{\label{fig:orgde67947}
Merkle-Damgård construction}
\end{figure}
\end{enumerate}

\subsubsection{MD5}
\label{sec:org11bba75}
The Message-Digest algorithm MD5 is a reasonably simple one-way hashing function that produces a 128-bit digest specified in 1992 in RFC 1321\cite{}. MD5 uses a Merkle-Damgård construction.
The MD5 algorithm work by partition the input message into blocks of 512 bits. It is done by always padding the message with a single set bit followed by a series of 0's until the message = 448 mod 512. That is, even when the original message has a length of 448 mod 512, a 1 is followed by 511 bits of 0's.
Next, a 64-bit representation of the message length mod 2\(^{\text{64}}\) is appended to the padded message.
The digest will be calculated in a 32-bit 4-word initialization (A, B, C, D), with the initial value:\\
\texttt{[} \texttt{A: 0x67542301}, \texttt{B: 0xefcdab89}, \texttt{C: 0x98badcfe}, \texttt{D: 0x10325476} \texttt{]}\\
and we use the following functions corresponding to each of the four rounds:\\
F(X, Y, Z) = XY \(\vee\) \(\neg{}\) X Z\\
G(X, Y, Z) = XZ \(\vee\) Y \(\neg{}\) Z\\
H(X, Y, Z) = X \(\oplus\) Y \(\oplus\) Z\\
I(X, Y, Z) = Y \(\oplus\) ( X \(\vee\) \(\neg{}\) Z)\\
These are defined as such to in "bitwise parallel" produce independent and unbiased bits in each of the rounds.

Process each 16-word block (512 bits) by copying it into a buffer X,
save the current digest buffer and perform the following rounds:
For each round a function [abcd k s i] denoting\\
a = b + (( a + round(b,c,d) + X[k] + T[i]) \(\lll\) s)
, where round denotes the function corresponding to that round.\footnote{this might be unecessary to show}
\begin{verbatim}
round 1  :: F
[ABCD  0  7  1] [DABC  1 12  2] [CDAB  2 17  3] [BCDA  3 22  4]
[ABCD  4  7  5] [DABC  5 12  6] [CDAB  6 17  7] [BCDA  7 22  8]
[ABCD  8  7  9] [DABC  9 12 10] [CDAB 10 17 11] [BCDA 11 22 12]
[ABCD 12  7 13] [DABC 13 12 14] [CDAB 14 17 15] [BCDA 15 22 16]
Round 2 :: G
[ABCD  1  5 17] [DABC  6  9 18] [CDAB 11 14 19] [BCDA  0 20 20]
[ABCD  5  5 21] [DABC 10  9 22] [CDAB 15 14 23] [BCDA  4 20 24]
[ABCD  9  5 25] [DABC 14  9 26] [CDAB  3 14 27] [BCDA  8 20 28]
[ABCD 13  5 29] [DABC  2  9 30] [CDAB  7 14 31] [BCDA 12 20 32]
Round 3 :: H
[ABCD  5  4 33] [DABC  8 11 34] [CDAB 11 16 35] [BCDA 14 23 36]
[ABCD  1  4 37] [DABC  4 11 38] [CDAB  7 16 39] [BCDA 10 23 40]
[ABCD 13  4 41] [DABC  0 11 42] [CDAB  3 16 43] [BCDA  6 23 44]
[ABCD  9  4 45] [DABC 12 11 46] [CDAB 15 16 47] [BCDA  2 23 48]
Round 4 :: I
[ABCD  0  6 49] [DABC  7 10 50] [CDAB 14 15 51] [BCDA  5 21 52]
[ABCD 12  6 53] [DABC  3 10 54] [CDAB 10 15 55] [BCDA  1 21 56]
[ABCD  8  6 57] [DABC 15 10 58] [CDAB  6 15 59] [BCDA 13 21 60]
[ABCD  4  6 61] [DABC 11 10 62] [CDAB  2 15 63] [BCDA  9 21 64]
\end{verbatim}
Next, increment each of the variables by its starting value.

The Digest will now be (A, B, C, D) in LE format.

It is worth noting that MD5 is not a very good hashing algorithm for cryptography, as collision attacks exist, but still show use for data integrity purposes and such.

\section{Implementation}
\label{sec:org7ed3dfd}
\subsection{MD5}
\label{sec:org68a08b1}

\subsubsection{naive}
\label{sec:orgbe29e06}
As explained in section\ref{SME}, SME consists of busses and processes. We can define the MD5 algorithm naively by following figure\ref{fig:Merkle} and using two busses and one simple process. Overall there are two approaches,
Firstly, we could let the arrows in the diagram denote the busses, such that we would have a bus denoting the message-block and one denoting the digest. However, this approach requires an extra bus, thus the alternative. Since we use a c\# implementation of SME, we can store the Digest locally inside the simpleProcess. Thus we will only require a bus with the message, corresponding to the downward-facing arrows and one for the Hash (the rightmost arrow).
we can define the Message bus as such:
\begin{verbatim}
public interface IMessage : IBus {
    [InitialValue(false)] bool Valid { get; set; }

    [FixedArrayLength(MAX_BUFFER_SIZE)]
    IFixedArray<byte> Message { get; set; }

    int BufferSize { get; set; }
    int MessageSize { get; set; }

    [InitialValue(true)] bool Last { get; set; }
    [InitialValue(true)] bool Head { get; set; }
    [InitialValue(false)] bool Set { get; set; }
}
\end{verbatim}
One can see there are multiple things to keep track of. First and foremost, all SME busses should have a flag for whether or not a bus has data inside of it. Secondly, A byte-array is used to store the message block itself. \texttt{BufferSize} will be updated for every iteration or tick, and denotes how many values in the buffer are set, essentially flag for when the message should be padded. MessageSize will be set in the initial tick and denote the length of the entire message used for the Merkle-Damgård strengthening.
The last 3 flags are used to handle some "edge-cases".
Head Denotes that the initialization vector should be reconstructed.
Last is used to denote when a block is the last in the message. The block cannot be filled with more than 447 bits.
Set is used in the cases where the initial 1 should be set but where the block is not the last in the message, for instance when the length of the message is 448.

The Digest on the other hand is simple. It only consists of a Valid flag and the Hash as an array of 4 32-bit words.

Except for the handling of the padding in relation to SME, the simple process works as explained in section\ref{MD5alg}

\subsubsection{First optimization approach}
\label{sec:orgbee67c1}
To make the algorithm more efficient, the length of the circuit produced in the VHDL code should be reduced. Meaning we want the simple process to do less. For the initial approach, we can notice that the compression function in MD5 works in rounds. We can thus structure the program as such using a simple diagram. in figure\ref{fig:MD5opt1} one can see we can split the hash function as a whole up into 5 simple processes and build a pipeline from this. One process for message formatting, and one for each of the 4 rounds. along with an Imessage bus and a Digest bus as described in section\ref{MD5naive}. This construction will create a pipeline where each process can run concurrently and potentially execute faster than the naive approach.
\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./MD5.png}
\caption{\label{fig:org9fac5aa}
MD5 pipeline}
\end{figure}

\subsubsection{Further optimizations}
\label{sec:orgdacf3ae}
This is just a question:
In Programming massively parallel hardware, I had a project where we were to implement a single pass parallel prefix Scan. And I know it is a bit different but, the idea is that each partition on the GPU will compute its own internal prefix scan and then wait for the previous one to finish and then add the prefix to every element in its internal scan. I was wondering if it could be worth trying a similar approach since a Merkel-Damgård construction is quite sequential in nature. So I thought if one could calculate everything that does not use the output from the previous tick, it might go faster, but I'm unsure whether such a thing could work on an FPGA since I still don't know too much about it.?

\section{Benchmarks}
\label{sec:org7566124}

\section{Discussion}
\label{sec:orgd5bf5d7}

\section{Conclusion}
\label{sec:org97c6992}

\bibliographystyle{unsrt}
\bibliography{ref}

\begin{appendix}

\end{appendix}
\end{document}
